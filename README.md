# ğŸ§ Ground-Truth-Free SER Human Evaluation

This repository hosts the **human evaluation interface** for the research project [**Ground-Truth-Free SER**](https://github.com/arozcan/ground-truth-free-ser), which aims to assess emotional expressiveness and naturalness in **synthetic speech** generated by various Text-to-Speech (TTS) systems.

## ğŸ” Overview

The application allows human raters to:
- Listen to speech samples synthesized by multiple Generative AI TTS models.
- Evaluate **how effectively each target emotion is conveyed**.
- Rate **how natural** each sample sounds on a 7-point scale.

All ratings are collected anonymously and securely stored for research purposes.

## âœ¨ Features
- ğŸ§ Integrated audio player for each sample  
- ğŸ”¢ Dual-rating system (emotion effectiveness & naturalness)  
- ğŸ§  Automatic session management (resumes from last rated sample)  
- ğŸ” Password-based rater login with XML-based user configuration  
- ğŸ’¾ Progress autosaving to CSV files per user  
- ğŸ§± Streamlit-based responsive web UI

## âš™ï¸ Installation

Clone the repository and install dependencies:
```bash
git clone https://github.com/arozcan/ground-truth-free-ser-human-eval.git
cd ground-truth-free-ser-human-eval
pip install -r requirements.txt
```

## ğŸš€ Run the App

Start the evaluation interface locally:
```bash
streamlit run app.py
```

Then open your browser at:
```
http://localhost:8501
```

## ğŸ” Data Privacy

- No personal or identifiable data is collected.
- Ratings are stored locally in per-user CSV files.
- Participants can withdraw anytime without providing a reason.

## ğŸ§© Related Project

This evaluation tool is part of the main repository:  
ğŸ‘‰ [**Ground-Truth-Free SER (Emotion Recognition & Validation Framework)**](https://github.com/arozcan/ground-truth-free-ser)

That repository includes:
- Emotion recognition models (WavLM, Whisper, Emotion2Vec+)
- Synthetic emotion dataset generation pipelines
- Automated emotion validation workflows

## ğŸ“„ Citation

If you use this interface or related datasets in your research, please cite:
```
A. R. Ozcan et al., "Ground-Truth-Free Framework for Validating Emotions in Synthetic Speech," 2025.
```